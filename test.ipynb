{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from models_multiple_GPUs import *\n",
    "from dataset_tools import DeepGlobeDatasetMultipleGPUs, custom_transform, custom_target_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Het systeem kan het opgegeven pad niet vinden: '/kaggle/input/deepglobe-dataset-new-ps-1224/cropped-1224/train/images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m image_dir_test   \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/deepglobe-dataset-new-ps-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPS_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/cropped-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPS_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test/images/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m mask_dir_test  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/deepglobe-dataset-new-ps-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPS_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/cropped-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPS_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test/gt/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 14\u001b[0m imagedataset_train \u001b[38;5;241m=\u001b[39m \u001b[43mDeepGlobeDatasetMultipleGPUs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_dir_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_target_transform\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, data_augmentation=data_augmentation)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m imagedataset_val \u001b[38;5;241m=\u001b[39m DeepGlobeDatasetMultipleGPUs(image_dir_val, mask_dir_val, transform\u001b[38;5;241m=\u001b[39mcustom_transform, target_transform\u001b[38;5;241m=\u001b[39mcustom_target_transform)\u001b[38;5;66;03m#, data_augmentation=data_augmentation)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m imagedataset_test \u001b[38;5;241m=\u001b[39m DeepGlobeDatasetMultipleGPUs(image_dir_test, mask_dir_test, transform\u001b[38;5;241m=\u001b[39mcustom_transform, target_transform\u001b[38;5;241m=\u001b[39mcustom_target_transform)\u001b[38;5;66;03m#, data_augmentation=data_augmentation)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corne\\Documents\\GitHub\\HiRes-Seg-CNN\\dataset_tools\\DataSets_multiple_GPUs.py:10\u001b[0m, in \u001b[0;36mDeepGlobeDatasetMultipleGPUs.__init__\u001b[1;34m(self, image_dir, mask_dir, transform, target_transform, data_augmentation, size)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_dir, mask_dir, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data_augmentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1224\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0_0.png\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_mask.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir \u001b[38;5;241m=\u001b[39m image_dir\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_dir \u001b[38;5;241m=\u001b[39m mask_dir\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Het systeem kan het opgegeven pad niet vinden: '/kaggle/input/deepglobe-dataset-new-ps-1224/cropped-1224/train/images/'"
     ]
    }
   ],
   "source": [
    "PS_train = 1224\n",
    "PS_val = 1224\n",
    "PS_test = 1224\n",
    "\n",
    "image_dir_train = f\"/kaggle/input/deepglobe-dataset-new-ps-{PS_train}/cropped-{PS_train}/train/images/\"\n",
    "mask_dir_train = f\"/kaggle/input/deepglobe-dataset-new-ps-{PS_train}/cropped-{PS_train}/train/gt/\"\n",
    "\n",
    "image_dir_val   = f\"/kaggle/input/deepglobe-dataset-new-ps-{PS_val}/cropped-{PS_val}/val/images/\"\n",
    "mask_dir_val  = f\"/kaggle/input/deepglobe-dataset-new-ps-{PS_val}/cropped-{PS_val}/val/gt/\"\n",
    "\n",
    "image_dir_test   = f\"/kaggle/input/deepglobe-dataset-new-ps-{PS_test}/cropped-{PS_test}/test/images/\"\n",
    "mask_dir_test  = f\"/kaggle/input/deepglobe-dataset-new-ps-{PS_test}/cropped-{PS_test}/test/gt/\"\n",
    "\n",
    "imagedataset_train = DeepGlobeDatasetMultipleGPUs(image_dir_train, mask_dir_train, transform=custom_transform, target_transform=custom_target_transform)#, data_augmentation=data_augmentation)\n",
    "imagedataset_val = DeepGlobeDatasetMultipleGPUs(image_dir_val, mask_dir_val, transform=custom_transform, target_transform=custom_target_transform)#, data_augmentation=data_augmentation)\n",
    "imagedataset_test = DeepGlobeDatasetMultipleGPUs(image_dir_test, mask_dir_test, transform=custom_transform, target_transform=custom_target_transform)#, data_augmentation=data_augmentation)\n",
    "\n",
    "dataloader_train = DeepGlobeDatasetMultipleGPUs(imagedataset_train, batch_size=2, shuffle=True, num_workers=2)\n",
    "dataloader_val = DeepGlobeDatasetMultipleGPUs(imagedataset_val, batch_size=2, shuffle=False, num_workers=2)\n",
    "dataloader_test = DeepGlobeDatasetMultipleGPUs(imagedataset_test, batch_size=2, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_unet = MultiGPU_ResNetUNet_with_comm(n_channels=3, resnet_type=\"resnet18\", n_classes=7, input_shape=(1224, 1224), num_comm_fmaps=64, devices=[\"cuda:0\"], depth=4, subdom_dist=(2, 2),\n",
    "                 bilinear=False, comm=True, complexity=16, dropout_rate=0.1, kernel_size=5, padding=2, communicator_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in encoders: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in resnet_unet.encoders[0].parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters in encoders:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_parallel_model(comm=True, plotting=True, num_epochs=50):\n",
    "\n",
    "    unet = MultiGPU_ResNetUNet_with_comm(n_channels=3, n_classes=7, input_shape=(1224, 1224), num_comm_fmaps=64, devices=[\"cuda:0\", \"cuda:1\"], depth=4, subdom_dist=(2, 2),\n",
    "                 bilinear=False, comm=comm, complexity=16, dropout_rate=0.1, kernel_size=5, padding=2, communicator_type=None)\n",
    "    unet.train()\n",
    "    if comm:\n",
    "        parameters = list(unet.encoders[0].parameters()) + list(unet.decoders[0].parameters()) + list(unet.communication_network.parameters()) \n",
    "    else:\n",
    "        parameters = list(unet.encoders[0].parameters()) + list(unet.decoders[0].parameters())\n",
    "        \n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "    loss = smp.losses.DiceLoss(mode=\"multiclass\")\n",
    "    losses = []\n",
    "\n",
    "    # Wrap your training loop with tqdm\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_losses = []  # Initialize losses for the epoch\n",
    "        for images, masks in tqdm(dataloader_train):\n",
    "            images = [im.float() for im in images]\n",
    "            masks = masks.to(\"cuda:0\", dtype=torch.long)\n",
    "\n",
    "            ## Forward propagation:\n",
    "            # Run batch through encoder\n",
    "            predictions = unet(images)\n",
    "            \n",
    "            ## Backward propagation\n",
    "            l = loss(predictions, masks)\n",
    "            l.backward()\n",
    "\n",
    "            losses.append(l.item())  # Append loss to global losses list\n",
    "            epoch_losses.append(l.item())  # Append loss to epoch losses list\n",
    "\n",
    "            # Sum gradients of model2 to model1 (Allreduce)\n",
    "#             with torch.no_grad():\n",
    "#                 for i in range(1, len(unet.encoders)):\n",
    "#                     for param1, param2 in zip(unet.encoders[0].parameters(), unet.encoders[i].parameters()):\n",
    "#                         param1.grad += param2.grad.to(\"cuda:0\")\n",
    "#                         param2.grad = None\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i in range(1, len(unet.decoders)):\n",
    "                    for param1, param2 in zip(unet.decoders[0].parameters(), unet.decoders[i].parameters()):\n",
    "                        param1.grad += param2.grad.to(\"cuda:0\")\n",
    "                        param2.grad = None\n",
    "\n",
    "            ## Parameter update\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Update model2 with the state of model1\n",
    "#             for i in range(1, len(unet.encoders)):\n",
    "#                 unet.encoders[i].load_state_dict(unet.encoders[0].state_dict())\n",
    "            for i in range(1, len(unet.decoders)):\n",
    "                unet.decoders[i].load_state_dict(unet.decoders[0].state_dict())\n",
    "\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Training the model {'with' if comm else 'without'} communication network took: {time.time() - start_time:.2f} seconds.\")\n",
    "    \n",
    "    if plotting:\n",
    "        unet.eval()\n",
    "        preds = unet(images)\n",
    "        \n",
    "        for i in range(masks.shape[0]):\n",
    "        \n",
    "            pred = torch.argmax(preds, dim=1)[i].cpu()\n",
    "            mask = masks.cpu()[i]\n",
    "\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.title(\"Mask\")\n",
    "            plt.imshow(mask[0], cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.title(\"Prediction\")\n",
    "            plt.imshow(pred, cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "    return unet, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
